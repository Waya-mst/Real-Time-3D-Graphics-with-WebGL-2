{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waya-mst/Real-Time-3D-Graphics-with-WebGL-2/blob/master/colab/websocket_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install_driver",
      "metadata": {
        "id": "install_driver",
        "outputId": "7e1db0b8-e780-48fa-d3a3-e01abc89a005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libnvidia-gl-535 is already the newest version (535.216.03-0ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!apt-get install libnvidia-gl-$(grep -oP 'NVIDIA UNIX x86_64 Kernel Module\\s+\\K[\\d.]+(?=\\s+)' /proc/driver/nvidia/version | grep -oE '^[0-9]+')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "write_requirements_txt",
      "metadata": {
        "id": "write_requirements_txt",
        "outputId": "1f0f2dbb-74f4-40a0-d61c-564daad75e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%file requirements.txt\n",
        "glcontext==2.5.0\n",
        "moderngl==5.10.0\n",
        "numpy\n",
        "opencv-python-headless\n",
        "websockets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "install_packages",
      "metadata": {
        "id": "install_packages",
        "outputId": "d1ec9f6d-a9f8-48a6-f906-df06fc81c7b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: glcontext==2.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: moderngl==5.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (5.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (14.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: ping3 in /usr/local/lib/python3.10/dist-packages (4.0.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install pyngrok ping3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "show_moderngl_config",
      "metadata": {
        "id": "show_moderngl_config",
        "outputId": "2ade58e8-fbf2-4ac9-c0db-1bb42c2786e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moderngl 5.10.0\n",
            "---------------\n",
            "vendor: NVIDIA Corporation\n",
            "renderer: Tesla T4/PCIe/SSE2\n",
            "version: 3.3.0 NVIDIA 535.104.05\n",
            "python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "platform: linux\n",
            "code: 330\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!curl -sL https://raw.githubusercontent.com/MsrOhkwr/vc2-remote-rendering/main/app/__main__.py | python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "make_directories",
      "metadata": {
        "id": "make_directories"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mkdir -p app\n",
        "!mkdir -p assets/glsl\n",
        "!mkdir -p colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "write_vertex_shader_glsl",
      "metadata": {
        "id": "write_vertex_shader_glsl",
        "outputId": "7a820877-52c4-475f-d3b4-ad1ad909cb55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assets/glsl/vertex_shader.glsl\n"
          ]
        }
      ],
      "source": [
        "%%file assets/glsl/vertex_shader.glsl\n",
        "#version 330 core\n",
        "\n",
        "in vec2 position_vertices;\n",
        "\n",
        "void main() { gl_Position = vec4(position_vertices, 0.0f, 1.0f); }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "write_fragment_shader_path_trace_glsl",
      "metadata": {
        "id": "write_fragment_shader_path_trace_glsl",
        "outputId": "9d347561-c607-410c-e47f-9c2edcebc4c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assets/glsl/fragment_shader_path_trace.glsl\n"
          ]
        }
      ],
      "source": [
        "%%file assets/glsl/fragment_shader_path_trace.glsl\n",
        "#version 330 core\n",
        "\n",
        "#define POW2(X) ((X) * (X))\n",
        "#define POW5(X) ((X) * (X) * (X) * (X) * (X))\n",
        "#define DEPTH_MAX (16)\n",
        "#define DELTA (0.01)\n",
        "#define PI (3.14159265359)\n",
        "\n",
        "#define BACKGROUND (0)\n",
        "#define DIFFUSE (1)\n",
        "#define MIRROR (2)\n",
        "#define GLASS (3)\n",
        "\n",
        "out vec4 input_color;\n",
        "out uvec4 seed_value;\n",
        "\n",
        "uniform sampler2D input_image;\n",
        "uniform usampler2D seed_image;\n",
        "uniform sampler2D background_image;\n",
        "\n",
        "uniform int sample_max;\n",
        "uniform int current_sample;\n",
        "uniform float theta;\n",
        "uniform float phi;\n",
        "uniform float move_x;\n",
        "uniform float move_y;\n",
        "\n",
        "ivec2 group_num = ivec2($width, $height);\n",
        "ivec2 group_idx = ivec2(gl_FragCoord.x, gl_FragCoord.y);\n",
        "\n",
        "struct Ray {\n",
        "  vec3 origin;    // 光線の始点\n",
        "  vec3 direction; // 光線の方向ベクトル\n",
        "  vec3 scatter;   // 散乱成分\n",
        "  int depth;      // 反射した回数\n",
        "};\n",
        "\n",
        "struct Hit {\n",
        "  float t;       // 光線の始点から衝突位置までの距離\n",
        "  vec3 position; // 衝突位置\n",
        "  vec3 normal;   // 衝突位置における法線ベクトル\n",
        "  vec3 scatter;  // 散乱成分\n",
        "  vec3 emission; // 放出成分\n",
        "  int material;  // 材質\n",
        "};\n",
        "\n",
        "struct Sphere {\n",
        "  vec3 center;   // 球の中心\n",
        "  float radius;  // 球の半径\n",
        "  vec3 scatter;  // 散乱成分\n",
        "  vec3 emission; // 放出成分\n",
        "  int material;  // 材質\n",
        "};\n",
        "\n",
        "uvec4 xors;\n",
        "\n",
        "// Xorshift による疑似乱数生成\n",
        "float rand() {\n",
        "  uint t = (xors[0] ^ (xors[0] << 11));\n",
        "  xors[0] = xors[1];\n",
        "  xors[1] = xors[2];\n",
        "  xors[2] = xors[3];\n",
        "  xors[3] = (xors[3] ^ (xors[3] >> 19)) ^ (t ^ (t >> 8));\n",
        "  return xors[3] / 4294967295.0f;\n",
        "}\n",
        "\n",
        "// 球と光線の交点\n",
        "bool hitSphere(const in Sphere sphere, const in Ray ray, inout Hit hit) {\n",
        "  // float a = dot(ray.direction, ray.direction);\n",
        "  // ray.direction は単位ベクトルであり，必ず 1 になるので省略\n",
        "  float b = dot(ray.origin, ray.direction) - dot(sphere.center, ray.direction);\n",
        "  float c = dot(ray.origin, ray.origin) - 2 * dot(ray.origin, sphere.center) +\n",
        "            dot(sphere.center, sphere.center) - POW2(sphere.radius);\n",
        "  float d = POW2(b) - c;\n",
        "\n",
        "  float t1, t2;\n",
        "  t1 = abs(b) + sqrt(d);\n",
        "  t1 = (b < 0) ? t1 : -t1;\n",
        "  t2 = c / t1;\n",
        "\n",
        "  float t;\n",
        "  if (d > 0) {\n",
        "    t = min(t1, t2);\n",
        "    if (0 < t && t < hit.t) {\n",
        "      hit.t = t;\n",
        "      hit.position = ray.origin + t * ray.direction;\n",
        "      hit.normal = normalize(hit.position - sphere.center);\n",
        "      hit.scatter = sphere.scatter;\n",
        "      hit.emission = sphere.emission;\n",
        "      hit.material = sphere.material;\n",
        "      return true;\n",
        "    }\n",
        "    t = max(t1, t2);\n",
        "    if (0 < t && t < hit.t) {\n",
        "      hit.t = t;\n",
        "      hit.position = ray.origin + t * ray.direction;\n",
        "      hit.normal = normalize(hit.position - sphere.center);\n",
        "      hit.scatter = sphere.scatter;\n",
        "      hit.emission = sphere.emission;\n",
        "      hit.material = sphere.material;\n",
        "      return true;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return false;\n",
        "}\n",
        "\n",
        "// 鏡面\n",
        "void mirror(inout Ray ray, const in Hit hit) {\n",
        "  if (dot(-ray.direction, hit.normal) < 0) {\n",
        "    ray.depth = DEPTH_MAX;\n",
        "    return;\n",
        "  }\n",
        "  ray.depth++;\n",
        "  ray.origin = hit.position + hit.normal * DELTA;\n",
        "  // 課題1：鏡面の作成\n",
        "  // ray.direction =\n",
        "  ray.scatter *= hit.scatter;\n",
        "}\n",
        "\n",
        "float fresnel(const in float n, const in float u) {\n",
        "  float f0 = POW2((n - 1) / (n + 1));\n",
        "  return f0 + (1 - f0) * POW5(1 - u);\n",
        "}\n",
        "\n",
        "// ガラス面\n",
        "void glass(inout Ray ray, const in Hit hit) {\n",
        "  ray.depth++;\n",
        "  float n = 1.5;\n",
        "  vec3 N;\n",
        "  float t = dot(-ray.direction, hit.normal);\n",
        "  if (t > 0.0f) {\n",
        "    n = 1.0f / n;\n",
        "    N = hit.normal;\n",
        "    t = t;\n",
        "  } else {\n",
        "    n = n / 1.0f;\n",
        "    N = -hit.normal;\n",
        "    t = -t;\n",
        "  }\n",
        "  if (rand() < fresnel(n, t) || n * length(cross(N, -ray.direction)) > 1) {\n",
        "    mirror(ray, hit);\n",
        "  } else {\n",
        "    ray.origin = hit.position - N * DELTA;\n",
        "    // 課題2：ガラス面の作成\n",
        "    // ray.direction =\n",
        "    ray.scatter *= hit.scatter;\n",
        "  }\n",
        "}\n",
        "\n",
        "// Image Based Lighting\n",
        "void background(inout Ray ray, inout Hit hit) {\n",
        "  ray.depth = DEPTH_MAX;\n",
        "  hit.emission =\n",
        "      texture(background_image,\n",
        "              vec2(-atan(ray.direction.x, ray.direction.z) / (2 * PI),\n",
        "                   acos(ray.direction.y) / PI))\n",
        "          .rgb;\n",
        "}\n",
        "\n",
        "vec3 random_direction() {\n",
        "  float theta = rand() * 2.0 * PI;\n",
        "  float phi = acos(2.0 * rand() - 1.0);\n",
        "\n",
        "  float x = sin(phi) * cos(theta);\n",
        "  float y = sin(phi) * sin(theta);\n",
        "  float z = cos(phi);\n",
        "\n",
        "  return normalize(vec3(x, y, z));\n",
        "}\n",
        "\n",
        "// 完全拡散反射面\n",
        "void diffuse(inout Ray ray, const in Hit hit) {\n",
        "  if (dot(-ray.direction, hit.normal) < 0) {\n",
        "    ray.depth = DEPTH_MAX;\n",
        "    ray.scatter = vec3(0.0f);\n",
        "    return;\n",
        "  }\n",
        "  ray.depth++;\n",
        "  float u = rand();\n",
        "  float z = sqrt(u);\n",
        "  float d = sqrt(1 - u);\n",
        "  float phi = rand() * 2.0f * PI;\n",
        "  vec3 random_vector = random_direction();\n",
        "\n",
        "  vec3 tangent =\n",
        "      normalize(random_vector - dot(random_vector, hit.normal) * hit.normal);\n",
        "  vec3 bitangent = normalize(cross(hit.normal, tangent));\n",
        "\n",
        "  ray.direction = normalize(tangent * d * cos(phi) + hit.normal * z +\n",
        "                            bitangent * d * sin(phi));\n",
        "\n",
        "  ray.origin = hit.position + hit.normal * DELTA;\n",
        "  ray.scatter *= hit.scatter;\n",
        "}\n",
        "\n",
        "void main() {\n",
        "  xors = texture(seed_image, gl_FragCoord.xy / group_num.xy);\n",
        "\n",
        "  vec4 color_present =\n",
        "      (current_sample == 1)\n",
        "          ? vec4(0.0f)\n",
        "          : texture(input_image, gl_FragCoord.xy / group_num.xy);\n",
        "\n",
        "  const vec3 eye = vec3(0.0f, 0.0f, 18.0f);\n",
        "\n",
        "  const int n_sphere = 2;\n",
        "  const Sphere spheres[n_sphere] =\n",
        "      Sphere[n_sphere](Sphere(vec3(0.0f), 4.0f, vec3(0.75f), vec3(0), DIFFUSE),\n",
        "                       Sphere(vec3(0.0f, -10000.05f, 0.0f), 9996.0f,\n",
        "                              vec3(0.75f), vec3(0), DIFFUSE));\n",
        "\n",
        "  mat3 M1 =\n",
        "      mat3(cos(theta), 0, sin(theta), 0, 1, 0, -sin(theta), 0, cos(theta));\n",
        "\n",
        "  mat3 M2 = mat3(1, 0, 0, 0, cos(phi), -sin(phi), 0, sin(phi), cos(phi));\n",
        "\n",
        "  for (int i = 0; i < sample_max; i++) {\n",
        "    vec4 color_next = vec4(0.0f);\n",
        "\n",
        "    vec3 position_screen = vec3(\n",
        "        float(group_idx.x + rand()) / group_num.x * 16.0f - 8.0f,\n",
        "        float(group_idx.y + rand()) / group_num.y * 9.0f - 4.5f, eye.z - 9.0f);\n",
        "\n",
        "    Ray ray = Ray(M1 * M2 * (eye + vec3(move_x, move_y, 0)),\n",
        "                  M1 * M2 * (normalize(position_screen - eye)), vec3(1.0f), 0);\n",
        "\n",
        "    Hit hit = Hit(1000.0f, vec3(0.0f), vec3(0.0f), vec3(0.0f), vec3(0.0f),\n",
        "                  BACKGROUND);\n",
        "\n",
        "    while (ray.depth < DEPTH_MAX) {\n",
        "      for (int i = 0; i < n_sphere; i++) {\n",
        "        hitSphere(spheres[i], ray, hit);\n",
        "      }\n",
        "\n",
        "      switch (hit.material) {\n",
        "      case BACKGROUND:\n",
        "        background(ray, hit);\n",
        "        break;\n",
        "      case DIFFUSE:\n",
        "        diffuse(ray, hit);\n",
        "        break;\n",
        "      case MIRROR:\n",
        "        mirror(ray, hit);\n",
        "        break;\n",
        "      case GLASS:\n",
        "        glass(ray, hit);\n",
        "        break;\n",
        "      }\n",
        "\n",
        "      color_next.rgb += hit.emission * ray.scatter;\n",
        "\n",
        "      hit.t = 10000.0f;\n",
        "      hit.material = BACKGROUND;\n",
        "    }\n",
        "\n",
        "    // 平均値の逐次計算\n",
        "    color_present += (color_next - color_present) / (current_sample + i);\n",
        "  }\n",
        "\n",
        "  input_color = color_present;\n",
        "  seed_value = xors;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "write_fragment_shader_post_process_glsl",
      "metadata": {
        "id": "write_fragment_shader_post_process_glsl",
        "outputId": "0880710a-6b81-473f-cbce-73b83166bca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assets/glsl/fragment_shader_post_process.glsl\n"
          ]
        }
      ],
      "source": [
        "%%file assets/glsl/fragment_shader_post_process.glsl\n",
        "#version 330 core\n",
        "\n",
        "#define POW2(X) ((X) * (X))\n",
        "\n",
        "out vec4 output_color;\n",
        "\n",
        "uniform sampler2D input_image;\n",
        "uniform float luminance_average;\n",
        "uniform float luminance_max;\n",
        "uniform float key_value;\n",
        "\n",
        "ivec2 group_num = ivec2($width, $height);\n",
        "\n",
        "// Tone Mapping\n",
        "vec4 toneMap(const in vec4 color) {\n",
        "  float luminance = 0.27 * color.r + 0.67 * color.g + 0.06 * color.b;\n",
        "  float luminance_fixed = key_value * (luminance / luminance_average);\n",
        "  float luminance_max_fixed = key_value * (luminance_max / luminance_average);\n",
        "\n",
        "  float luminance_mapped = luminance_fixed *\n",
        "                           (1 + luminance_fixed / POW2(luminance_max_fixed)) /\n",
        "                           (1 + luminance_fixed);\n",
        "\n",
        "  vec3 color_fixed = color.rgb * (luminance_mapped / luminance);\n",
        "\n",
        "  return vec4(clamp(color_fixed, 0, 1), 1.0f);\n",
        "}\n",
        "\n",
        "// Gamma Correction\n",
        "vec4 gammaCorrect(const in vec4 color, const in float gamma) {\n",
        "  float c = 1.0f / gamma;\n",
        "  return vec4(pow(color.r, c), pow(color.g, c), pow(color.b, c), 1.0f);\n",
        "}\n",
        "\n",
        "void main() {\n",
        "  vec4 color = texture(input_image, gl_FragCoord.xy / group_num.xy);\n",
        "  color = toneMap(color);\n",
        "  output_color = gammaCorrect(color, 2.2);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "write_server_py",
      "metadata": {
        "id": "write_server_py",
        "outputId": "ddef2597-c0b2-4808-df4d-74c9f2cf3dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app/server.py\n"
          ]
        }
      ],
      "source": [
        "%%file app/server.py\n",
        "import asyncio\n",
        "import json\n",
        "\n",
        "from websockets.server import serve\n",
        "\n",
        "from render import Context\n",
        "\n",
        "\n",
        "class WebSocket:\n",
        "    def __init__(self, context):\n",
        "        self.context = context\n",
        "\n",
        "    async def task(self, websocket):\n",
        "        # キャンセルされるまでサンプリングとレンダリング結果画像の送信を繰り返す\n",
        "        i = 0\n",
        "        while True:\n",
        "            print([\"-\", \"/\", \"|\", \"\\\\\"][i % 4], \"\\r\", end=\"\")\n",
        "            try:\n",
        "                self.context.current_sample = i * self.context.sample_per_frame + 1\n",
        "                i += 1\n",
        "                next_frame = i * self.context.sample_per_frame\n",
        "\n",
        "                sample_max = self.context.sample_per_frame\n",
        "                if self.context.max_spp:\n",
        "                    if next_frame > int(self.context.max_spp):\n",
        "                        sample_max = (\n",
        "                            int(self.context.max_spp) % self.context.sample_per_frame\n",
        "                        )\n",
        "                        next_frame = int(self.context.max_spp)\n",
        "\n",
        "                self.context.render(sample_max)\n",
        "\n",
        "                await asyncio.gather(\n",
        "                    # レンダリング結果画像を送信する（識別子：0000）\n",
        "                    websocket.send(b\"0000\" + self.context.get_binary()),\n",
        "                    # 現在の1画素あたりのサンプル数を送信する（識別子：0001）\n",
        "                    websocket.send(b\"0001\" + bytes(next_frame)),\n",
        "                )\n",
        "\n",
        "                if self.context.max_spp:\n",
        "                    if next_frame >= int(self.context.max_spp):\n",
        "                        break\n",
        "            except RuntimeError as e:\n",
        "                print(\"Runtime Error:\", e)\n",
        "                break\n",
        "            except ValueError as e:\n",
        "                print(\"ValueError:\", e)\n",
        "                break\n",
        "\n",
        "    async def echo(self, websocket):\n",
        "        current_task = None\n",
        "        print(\"init\")\n",
        "        print(\"current_task: \", current_task)\n",
        "\n",
        "        # クライアントからの接続要求を待ち受ける\n",
        "        while True:\n",
        "            message = json.loads(await websocket.recv())\n",
        "            if \"theta\" in message:\n",
        "                self.context.theta = message[\"theta\"]\n",
        "            if \"phi\" in message:\n",
        "                self.context.phi = message[\"phi\"]\n",
        "            if \"moveX\" in message:\n",
        "                self.context.move_x = message[\"moveX\"]\n",
        "            if \"moveY\" in message:\n",
        "                self.context.move_y = message[\"moveY\"]\n",
        "            if \"maxSpp\" in message:\n",
        "                self.context.max_spp = message[\"maxSpp\"]\n",
        "            if \"keyValue\" in message:\n",
        "                self.context.key_value = message[\"keyValue\"]\n",
        "\n",
        "            for task in asyncio.all_tasks():\n",
        "                if task.get_coro().__name__ == \"task\" and not task.done():\n",
        "                    task.cancel()\n",
        "\n",
        "            # レンダリングタスクを実行する\n",
        "            current_task = asyncio.create_task(self.task(websocket))\n",
        "\n",
        "            print(\"task assigned\")\n",
        "            print(\"current_task: \", current_task)\n",
        "\n",
        "    async def main(self, host, port):\n",
        "        async with serve(self.echo, host, port):\n",
        "            print(\"Listening at: \", f\"ws://{host}:{port}\")\n",
        "            await asyncio.Future()  # run forever\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ctx = Context(width=960, height=540, sample_per_frame=64)\n",
        "    ctx.bind_data(env_map_path=\"assets/hdr/museum_of_ethnography_1k.hdr\")\n",
        "    ctx.create_program()\n",
        "    ws = WebSocket(ctx)\n",
        "    asyncio.run(ws.main(\"127.0.0.1\", 8030))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "write_render_py",
      "metadata": {
        "id": "write_render_py",
        "outputId": "28f9e5ef-7be1-400b-f687-e7f084080de7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app/render.py\n"
          ]
        }
      ],
      "source": [
        "%%file app/render.py\n",
        "import io\n",
        "import os\n",
        "import platform\n",
        "from string import Template\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import moderngl\n",
        "\n",
        "\n",
        "class Context:\n",
        "    ATTACHMENT_INDEX_OUTPUT_COLOR = 0\n",
        "    ATTACHMENT_INDEX_INPUT_COLOR = 1\n",
        "    ATTACHMENT_INDEX_SEED_VALUE = 2\n",
        "    TEXTURE_UNIT_INPUT_IMAGE = 1\n",
        "    TEXTURE_UNIT_SEED_IMAGE = 2\n",
        "    TEXTURE_UNIT_BACKGROUND_IMAGE = 3\n",
        "\n",
        "    def __init__(self, width=960, height=540, sample_per_frame=1):\n",
        "        kwargs = {\n",
        "            \"standalone\": True,\n",
        "            \"require\": 330,\n",
        "        }\n",
        "        if platform.system() == \"Linux\" and \"LD_PRELOAD\" not in os.environ:\n",
        "            kwargs[\"backend\"] = \"egl\"\n",
        "        self.context = moderngl.create_context(**kwargs)\n",
        "\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.sample_per_frame = sample_per_frame\n",
        "\n",
        "        with open(\"assets/glsl/vertex_shader.glsl\", encoding=\"utf-8\") as vs_f:\n",
        "            self.vertex_shader_str = vs_f.read()\n",
        "        with open(\n",
        "            \"assets/glsl/fragment_shader_path_trace.glsl\", encoding=\"utf-8\"\n",
        "        ) as fs_f:\n",
        "            self.fragment_shader_str = fs_f.read()\n",
        "        with open(\n",
        "            \"assets/glsl/fragment_shader_post_process.glsl\", encoding=\"utf-8\"\n",
        "        ) as fs_f:\n",
        "            self.post_process_str = fs_f.read()\n",
        "\n",
        "        self.current_sample = 1\n",
        "        self.theta = 0\n",
        "        self.phi = 0\n",
        "        self.move_x = 0\n",
        "        self.move_y = 0\n",
        "        self.max_spp = 0\n",
        "        self.key_value = 0.18\n",
        "\n",
        "        self.switch = 0\n",
        "        self.output_image = None\n",
        "        self.input_image_list = None\n",
        "        self.seed_image_list = None\n",
        "\n",
        "        self.program_path_trace = None\n",
        "        self.program_post_process = None\n",
        "        self.vao_path_trace = None\n",
        "        self.vao_post_process = None\n",
        "        self.fbo = None\n",
        "\n",
        "    def bind_data(self, env_map_path):\n",
        "        data = np.zeros((self.height, self.width, 4)).astype(\"float32\").tobytes()\n",
        "\n",
        "        # 送信用画像（トーンマップおよびガンマ変換適用済み）\n",
        "        self.output_image = self.context.texture(\n",
        "            (self.width, self.height), components=4, dtype=\"f4\"\n",
        "        )\n",
        "\n",
        "        # サンプリングを再開するために用いる raw 画像\n",
        "        self.input_image_list = [\n",
        "            self.context.texture((self.width, self.height), 4, data, dtype=\"f4\"),\n",
        "            self.context.texture((self.width, self.height), 4, data, dtype=\"f4\"),\n",
        "        ]\n",
        "\n",
        "        seed = (\n",
        "            np.random.default_rng(0)\n",
        "            .integers(\n",
        "                low=0, high=2**32, size=(self.width, self.height, 4), dtype=np.uint32\n",
        "            )\n",
        "            .tobytes()\n",
        "        )\n",
        "\n",
        "        # 乱数のシード画像（各画素で別々のシード値を使用）\n",
        "        self.seed_image_list = [\n",
        "            self.context.texture((self.width, self.height), 4, seed, dtype=\"u4\"),\n",
        "            self.context.texture((self.width, self.height), 4, seed, dtype=\"u4\"),\n",
        "        ]\n",
        "\n",
        "        # 環境マップ画像\n",
        "        env_map = cv2.imread(env_map_path, cv2.IMREAD_UNCHANGED)\n",
        "        env_map = cv2.cvtColor(env_map, cv2.COLOR_BGRA2RGBA)\n",
        "        env_map = env_map.reshape((env_map.shape[1], env_map.shape[0], 4))\n",
        "        background_image = self.context.texture(\n",
        "            (env_map.shape[0], env_map.shape[1]), 4, env_map, dtype=\"f4\"\n",
        "        )\n",
        "        background_image.write(data=env_map.astype(\"float32\").tobytes())\n",
        "        self.context.sampler(texture=background_image).use(\n",
        "            Context.TEXTURE_UNIT_BACKGROUND_IMAGE\n",
        "        )\n",
        "\n",
        "    def create_program(self):\n",
        "        self.program_path_trace = self.context.program(\n",
        "            vertex_shader=self.vertex_shader_str,\n",
        "            fragment_shader=Template(self.fragment_shader_str).substitute(\n",
        "                width=self.width,\n",
        "                height=self.height,\n",
        "            ),\n",
        "            fragment_outputs={\n",
        "                \"output_color\": Context.ATTACHMENT_INDEX_OUTPUT_COLOR,\n",
        "                \"input_color\": Context.ATTACHMENT_INDEX_INPUT_COLOR,\n",
        "                \"seed_value\": Context.ATTACHMENT_INDEX_SEED_VALUE,\n",
        "            },\n",
        "        )\n",
        "        self.program_post_process = self.context.program(\n",
        "            vertex_shader=self.vertex_shader_str,\n",
        "            fragment_shader=Template(self.post_process_str).substitute(\n",
        "                width=self.width,\n",
        "                height=self.height,\n",
        "            ),\n",
        "            fragment_outputs={\n",
        "                \"output_color\": Context.ATTACHMENT_INDEX_OUTPUT_COLOR,\n",
        "            },\n",
        "        )\n",
        "        vbo = self.context.buffer(\n",
        "            np.array(\n",
        "                [\n",
        "                    [-1, -1],\n",
        "                    [-1, 3],\n",
        "                    [3, -1],\n",
        "                ],\n",
        "                dtype=\"f4\",\n",
        "            )\n",
        "        )\n",
        "        self.vao_path_trace = self.context.vertex_array(\n",
        "            self.program_path_trace,\n",
        "            [(vbo, \"2f /v\", \"position_vertices\")],\n",
        "        )\n",
        "        self.vao_post_process = self.context.vertex_array(\n",
        "            self.program_post_process,\n",
        "            [(vbo, \"2f /v\", \"position_vertices\")],\n",
        "        )\n",
        "\n",
        "    def path_trace(self, sample_max, program):\n",
        "        program[\"sample_max\"].value = sample_max\n",
        "        program[\"current_sample\"].value = self.current_sample\n",
        "        program[\"theta\"].value = self.theta\n",
        "        program[\"phi\"].value = self.phi\n",
        "        program[\"move_x\"].value = self.move_x\n",
        "        program[\"move_y\"].value = self.move_y\n",
        "\n",
        "        program[\"input_image\"].value = Context.TEXTURE_UNIT_INPUT_IMAGE\n",
        "        program[\"seed_image\"].value = Context.TEXTURE_UNIT_SEED_IMAGE\n",
        "        program[\"background_image\"].value = Context.TEXTURE_UNIT_BACKGROUND_IMAGE\n",
        "\n",
        "        self.fbo = self.context.framebuffer(\n",
        "            [\n",
        "                self.output_image,\n",
        "                self.input_image_list[self.switch],\n",
        "                self.seed_image_list[self.switch],\n",
        "            ]\n",
        "        )\n",
        "        self.fbo.use()\n",
        "        self.switch = ~self.switch & 1\n",
        "        self.context.sampler(\n",
        "            texture=self.input_image_list[self.switch],\n",
        "            filter=(moderngl.Context.NEAREST, moderngl.Context.NEAREST),\n",
        "        ).use(Context.ATTACHMENT_INDEX_INPUT_COLOR)\n",
        "        self.context.sampler(\n",
        "            texture=self.seed_image_list[self.switch],\n",
        "            filter=(moderngl.Context.NEAREST, moderngl.Context.NEAREST),\n",
        "        ).use(Context.ATTACHMENT_INDEX_SEED_VALUE)\n",
        "        self.context.clear()\n",
        "        self.vao_path_trace.render(moderngl.Context.TRIANGLES)\n",
        "\n",
        "    def post_process(self, luminance_average, luminance_max, program):\n",
        "        program[\"input_image\"].value = Context.TEXTURE_UNIT_INPUT_IMAGE\n",
        "        program[\"luminance_average\"].value = luminance_average\n",
        "        program[\"luminance_max\"].value = luminance_max\n",
        "        program[\"key_value\"].value = self.key_value\n",
        "\n",
        "        self.fbo = self.context.framebuffer(\n",
        "            [\n",
        "                self.output_image,\n",
        "                self.input_image_list[self.switch],\n",
        "                self.seed_image_list[self.switch],\n",
        "            ]\n",
        "        )\n",
        "        self.fbo.use()\n",
        "        self.switch = ~self.switch & 1\n",
        "        self.context.sampler(\n",
        "            texture=self.input_image_list[self.switch],\n",
        "            filter=(moderngl.Context.NEAREST, moderngl.Context.NEAREST),\n",
        "        ).use(Context.ATTACHMENT_INDEX_INPUT_COLOR)\n",
        "        self.context.sampler(\n",
        "            texture=self.seed_image_list[self.switch],\n",
        "            filter=(moderngl.Context.NEAREST, moderngl.Context.NEAREST),\n",
        "        ).use(Context.ATTACHMENT_INDEX_SEED_VALUE)\n",
        "        self.context.clear()\n",
        "        self.vao_post_process.render(moderngl.Context.TRIANGLES)\n",
        "\n",
        "    def read_buffer(self, attachment):\n",
        "        if self.fbo is None:\n",
        "            raise RuntimeError(\"frame buffer object has not been assigned\")\n",
        "\n",
        "        return np.frombuffer(\n",
        "            self.fbo.read(\n",
        "                components=4,\n",
        "                dtype=\"f4\",\n",
        "                attachment=attachment,\n",
        "            ),\n",
        "            dtype=\"f4\",\n",
        "        ).reshape(self.height, self.width, 4)\n",
        "\n",
        "    def render(self, sample_max):\n",
        "        if self.program_path_trace is None:\n",
        "            raise RuntimeError(\"program_path_trace has not been created\")\n",
        "        if self.program_post_process is None:\n",
        "            raise RuntimeError(\"program_post_process has not been created\")\n",
        "        if self.vao_path_trace is None:\n",
        "            raise RuntimeError(\"vao_path_trace has not been assigned\")\n",
        "        if self.vao_post_process is None:\n",
        "            raise RuntimeError(\"vao_path_process has not been assigned\")\n",
        "        if self.output_image is None:\n",
        "            raise RuntimeError(\"output_image has not been assigned\")\n",
        "        if self.input_image_list is None:\n",
        "            raise RuntimeError(\"input_image_list has not been assigned\")\n",
        "        if self.seed_image_list is None:\n",
        "            raise RuntimeError(\"seed_image_list has not been assigned\")\n",
        "\n",
        "        if self.fbo is not None:\n",
        "            self.fbo.release()\n",
        "\n",
        "        self.path_trace(sample_max, self.program_path_trace)\n",
        "\n",
        "        buffer = self.read_buffer(Context.ATTACHMENT_INDEX_INPUT_COLOR)\n",
        "        luminance = (\n",
        "            0.27 * buffer[:, :, 0] + 0.67 * buffer[:, :, 1] + 0.06 * buffer[:, :, 2]\n",
        "        )\n",
        "        luminance_average = np.exp(\n",
        "            np.mean(np.log(np.finfo(np.float32).tiny + luminance))\n",
        "        )\n",
        "        luminance_max = buffer.max()\n",
        "\n",
        "        self.post_process(luminance_average, luminance_max, self.program_post_process)\n",
        "\n",
        "        self.switch = ~self.switch & 1\n",
        "\n",
        "    def get_buffer(self):\n",
        "        buffer = self.read_buffer(Context.ATTACHMENT_INDEX_OUTPUT_COLOR)\n",
        "        buffer = np.flipud(buffer)\n",
        "        buffer = cv2.cvtColor(buffer, cv2.COLOR_RGBA2BGRA)\n",
        "        buffer = (buffer * 255).astype(np.uint8)\n",
        "        return buffer\n",
        "\n",
        "    def get_binary(self):\n",
        "        buffer = self.get_buffer()\n",
        "        is_success, binary = cv2.imencode(\".jpg\", buffer)\n",
        "        with io.BytesIO(binary) as b:\n",
        "            return b.getvalue()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "download_environment_map",
      "metadata": {
        "id": "download_environment_map",
        "outputId": "a79b510f-3d15-4ca5-e2f4-895e578fb48f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1619k  100 1619k    0     0  3451k      0 --:--:-- --:--:-- --:--:-- 3445k\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!(mkdir -p assets/hdr && cd assets/hdr && curl -O https://dl.polyhaven.org/file/ph-assets/HDRIs/hdr/1k/museum_of_ethnography_1k.hdr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "describe_instance_information",
      "metadata": {
        "id": "describe_instance_information",
        "outputId": "ef7fde54-00ef-423b-cdb6-b130cf062ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'city': 'North Charleston',\n",
            " 'country': 'US',\n",
            " 'hostname': '252.147.73.34.bc.googleusercontent.com',\n",
            " 'ip': '34.73.147.252',\n",
            " 'loc': '32.8546,-79.9748',\n",
            " 'org': 'AS396982 Google LLC',\n",
            " 'postal': '29415',\n",
            " 'readme': 'https://ipinfo.io/missingauth',\n",
            " 'region': 'South Carolina',\n",
            " 'timezone': 'America/New_York'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "from pprint import pprint\n",
        "from urllib import request\n",
        "\n",
        "ipinfo = json.loads(request.urlopen(\"https://ipinfo.io\").read())\n",
        "pprint(ipinfo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "write_tunnel_py",
      "metadata": {
        "id": "write_tunnel_py",
        "outputId": "b0c29c44-6817-4ad1-8dc7-5454b3070ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting colab/tunnel.py\n"
          ]
        }
      ],
      "source": [
        "%%file colab/tunnel.py\n",
        "from ping3 import ping\n",
        "from pyngrok import conf, ngrok\n",
        "\n",
        "\n",
        "class Tunnel:\n",
        "    # Ngrok がサポートするリージョンのリスト\n",
        "    # cf.) https://ngrok.com/docs/ngrok-agent/config/#region\n",
        "    region_list = [\"us\", \"eu\", \"ap\", \"au\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "    def __init__(self, token):\n",
        "        ngrok.set_auth_token(token)\n",
        "        self.region_priority_list = Tunnel.region_list\n",
        "\n",
        "    def calc_region_priority(self):\n",
        "        key_list = []\n",
        "        for region in Tunnel.region_list:\n",
        "            public_url = self.get_public_url(region=region)\n",
        "            key = float(\"inf\")\n",
        "            key = ping(public_url.replace(\"https://\", \"\").split(\":\")[0])\n",
        "            ngrok.disconnect(public_url)\n",
        "            ngrok.kill()\n",
        "            key_list.append(key)\n",
        "\n",
        "        self.region_priority_list, _ = zip(\n",
        "            *sorted(zip(Tunnel.region_list, key_list), key=lambda x: x[1])\n",
        "        )\n",
        "\n",
        "        print(self.region_priority_list, _)\n",
        "\n",
        "    def get_public_url(self, port=80, region=None):\n",
        "        if region == None:\n",
        "            region = self.region_priority_list[0]\n",
        "        pyngrok_config = conf.PyngrokConfig(region=region)\n",
        "        return ngrok.connect(\n",
        "            port, proto=\"http\", pyngrok_config=pyngrok_config\n",
        "        ).public_url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "start_tunnel",
      "metadata": {
        "id": "start_tunnel",
        "outputId": "bd98788d-98dd-40dc-f4de-b97edefee9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:25+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-91b71833-da34-46c9-9ca2-065dc6191f42 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:26+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-69209987-6f2e-46ea-b3a1-c109f87d86b0 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:27+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-5f415a45-51e9-43ef-a911-de69d752a1ab acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:28+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-1cbceec9-b24f-44d7-80ed-6c7c83ecafec acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:29+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-180abdaa-a7cf-424e-8444-67d529fe7176 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T02:00:31+0000 lvl=warn msg=\"Stopping forwarder\" name=http-80-ad999cc9-8abd-40eb-a801-c036aac3e70d acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('us', 'jp', 'sa', 'in', 'eu', 'au', 'ap') (False, 0.03493809700012207, 0.03510451316833496, 0.03562736511230469, 0.035681724548339844, 0.035950660705566406, 0.036116838455200195)\n",
            "wss://bede-34-73-147-252.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from colab.tunnel import Tunnel\n",
        "\n",
        "# Ngrok の認証トークンを指定する\n",
        "token = \"2Rw7KkFJu9tVvr316PkrQkGqK9P_7kKEpWwzbvsCgy6hgA9rn\"\n",
        "\n",
        "tunnel = Tunnel(token)\n",
        "\n",
        "# Google Colaboratory のサーバと最も低遅延で通信できるトンネルを見つける\n",
        "tunnel.calc_region_priority()\n",
        "\n",
        "# グローバルアクセス可能なURLを取得する\n",
        "public_url = tunnel.get_public_url(port=8030)\n",
        "print(public_url.replace(\"https://\", \"wss://\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "start_up_server",
      "metadata": {
        "id": "start_up_server",
        "outputId": "b853d828-d419-40fa-c645-b8730f790982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/app/server.py:4: DeprecationWarning: websockets.server.serve is deprecated\n",
            "  from websockets.server import serve\n",
            "Listening at:  ws://127.0.0.1:8030\n",
            "init\n",
            "current_task:  None\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-8' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-277' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-284' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-285' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-286' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-289' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-290' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-293' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-324' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-325' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-326' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-329' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-334' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-335' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-338' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-339' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-340' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-341' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-342' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-345' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-346' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-347' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-348' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-351' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-352' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-353' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-356' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-383' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-384' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-385' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-386' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-389' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-390' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-391' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-394' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-395' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-396' coro=<WebSocket.task() running at /content/app/server.py:13>>\n",
            "task assigned\n",
            "current_task:  <Task pending name='Task-399' coro=<WebSocket.task() running at /content/app/server.py:13>>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python app/server.py\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}